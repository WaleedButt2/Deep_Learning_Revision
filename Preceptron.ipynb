{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'x1': [0, 0, 1, 1],\n",
    "    'x2': [0, 1, 0, 1],\n",
    "    'y':  [0, 0, 0, 1]  # AND logic: only 1 AND 1 is 1, rest are 0\n",
    "}\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "x1=df.pop('x1')\n",
    "x2=df.pop('x2')\n",
    "y=df.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a preceptron that functions as a AND gate\n",
    "# z = w1x1+w2x2+b\n",
    "# we will binary cross entropy loss function 0 or 1 classification\n",
    "# Loss = -1/n sum(yi * log(y'i)+(1-yi)*log(1-y'i))\n",
    "# dL/dy' = (-y/y' + (1-y)/(1-y'))\n",
    "# a = sigmoid(z)\n",
    "# a=y'\n",
    "# dL/da = (-y/a + (1-y)/(1-a))\n",
    "def L(y,a):\n",
    "    n=len(y)\n",
    "    return -1/n * np.sum(y * np.log(a) + (1 - y) * np.log(1 - a))\n",
    "def ddLa(y,a):\n",
    "    return -y/a + (1-y)/(1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=sigmoid(z)\n",
    "# da/dz = a(1-a)\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "def ddaz(a):\n",
    "    return a * (1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = w1x1+w2x2+b\n",
    "# dz/dw1 = x1\n",
    "# dz/dw2 = x2\n",
    "# dz/db = 1\n",
    "# dL/dw1 = dL/da * da/dz * dz/dw1\n",
    "# dL/dw2 = dL/da * da/dz * dz/dw2\n",
    "# dL/db = dL/da * da/dz * dz/db\n",
    "def ddLW1(y,a,x1):\n",
    "    return ddLa(y,a)*ddaz(a)*x1\n",
    "def ddLW2(y,a,x2):\n",
    "    return ddLa(y,a)*ddaz(a)*x2\n",
    "def ddLb(y,a):\n",
    "    return ddLa(y,a)*ddaz(a)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update equations are same\n",
    "# w1 = w1 - learning_rate*dl/dw1\n",
    "# w2 = w2 - learning_rate*dl/dw2\n",
    "# b = b - learning_rate*dl/db\n",
    "def forward(x1,x2,w1,w2,b):\n",
    "    # find z\n",
    "    z = w1 * x1 + w2 * x2 + b\n",
    "    #print(z)\n",
    "    a = sigmoid(z)\n",
    "    #print(a)\n",
    "    return z,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(y,a,w1,w2,b,x1,x2,learning_rate):\n",
    "    w1=w1-learning_rate*ddLW1(y,a,x1)\n",
    "    w2=w2-learning_rate*ddLW2(y,a,x2)\n",
    "    b=b-learning_rate*ddLb(y,a)\n",
    "    return w1,w2,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.random.rand() \n",
    "w2=np.random.rand() \n",
    "b=np.random.rand() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=100\n",
    "learning_rate=0.1\n",
    "\n",
    "for i in range(steps):\n",
    "    z,a=forward(x1,x2,w1,w2,b)\n",
    "    w1,w2,b=optimize(y,a,w1,w2,b,x1,x2,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.117051\n",
       "1    0.056164\n",
       "2    0.058393\n",
       "3    0.969696\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do it for football.csv file\n",
    "df = pd.read_csv('football.csv')\n",
    "df=df.drop('Team',axis=1)\n",
    "df.corr()\n",
    "y = df.pop('Points').to_numpy()\n",
    "X = df.to_numpy() \n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(X.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6x20\n",
    "#20x1\n",
    "#6x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_shape, learning_rate):\n",
    "        self.w = np.random.rand(input_shape)\n",
    "        self.b = np.random.rand()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z = np.dot(x, self.w) + self.b\n",
    "        self.a = self.relu(self.z)\n",
    "        return self.a\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def optimize(self, x, y):\n",
    "        n = len(y)\n",
    "        dw = np.dot(x.T, (self.a - y)) / n\n",
    "        db = np.sum(self.a - y) / n\n",
    "        self.w -= self.learning_rate * dw\n",
    "        self.b -= self.learning_rate * db\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0,z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Perceptron(X.shape[1],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=1000\n",
    "learning_rate=0.1\n",
    "\n",
    "for i in range(steps):\n",
    "    p.forward(X_train)\n",
    "    p.optimize(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.785772610171847"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=p.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Games</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Draws</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Goals Allowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Games  Wins  Losses  Draws  Goals  Goals Allowed\n",
       "0      38    26       9      3     79             36\n",
       "1      38    24       8      6     67             30\n",
       "2      38    24       5      9     87             45\n",
       "3      38    21       8      9     74             52\n",
       "4      38    18      12      8     53             37\n",
       "5      38    17      13      8     66             38\n",
       "6      38    15       8     15     48             57\n",
       "7      38    12      14     12     46             47\n",
       "8      38    14       8     16     49             53\n",
       "9      38    12      10     16     55             51\n",
       "10     38    12       9     17     46             54\n",
       "11     38    12       9     17     35             47\n",
       "12     38    10      14     14     36             44\n",
       "13     38    10      14     14     38             49\n",
       "14     38    11      10     17     45             57\n",
       "15     38     9      13     16     44             62\n",
       "16     38    10      10     18     29             51\n",
       "17     38     9       9     20     41             64\n",
       "18     38     8       6     24     33             63\n",
       "19     38     5      13     20     30             64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_shape, learning_rate):\n",
    "        self.w = np.random.rand(input_shape)\n",
    "        self.b = np.random.rand()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z = np.dot(x, self.w) + self.b\n",
    "        self.a = self.sigmoid(self.z)\n",
    "        return self.a\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def optimize(self, x, y):\n",
    "        n = len(y)\n",
    "        dw = np.dot(x.T, (self.a - y)) / n\n",
    "        db = np.sum(self.a - y) / n\n",
    "        self.w -= self.learning_rate * dw\n",
    "        self.b -= self.learning_rate * db\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0,z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do it for football.csv file\n",
    "df = pd.read_csv('./titatnic.csv')\n",
    "df=df.drop('Passengerid',axis=1)\n",
    "df=df.dropna(axis=0)\n",
    "df.corr()\n",
    "y = df.pop('2urvived').to_numpy()\n",
    "df=df.drop(['zero','zero.1','zero.2','zero.3','zero.4','zero.5','zero.6','zero.7','zero.8','zero.9','zero.10','zero.11','zero.12','zero.13','zero.14','zero.15','zero.16','zero.17','zero.18'],axis=1)\n",
    "X = df.to_numpy() \n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.read_csv('./agaricus-lepiota.data',header=None)\n",
    "df=df.dropna(axis=0)\n",
    "label_encoder = LabelEncoder()\n",
    "arr=np.unique(df.values)\n",
    "label_encoder.fit(arr)\n",
    "for i in range(23):\n",
    "    df[i]=label_encoder.transform(df[i])\n",
    "y = df.pop(0).to_numpy()\n",
    "X = df.to_numpy() \n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train=X_train.reshape(X_train.shape[1],X_train.shape[0])\n",
    "# X_test=X_test.reshape(X_test.shape[1],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Perceptron(X.shape[1],learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7480916030534351\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n",
      "0.7519083969465649\n"
     ]
    }
   ],
   "source": [
    "steps=100\n",
    "learning_rate=0.0001\n",
    "\n",
    "for i in range(steps):\n",
    "    p.forward(X_train)\n",
    "    p.optimize(X_train,y_train)\n",
    "    pred=p.predict(X_test)\n",
    "    y_pred = np.where(pred >= 0.5, 1, 0)\n",
    "    print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
